\documentclass{beamer}

% Imported Packages
\usepackage[utf8]{inputenc}
\usepackage{xcolor}

% Theme
\usetheme[white, compactlogo]{Wisconsin}

%This block of code defines the information to appear in the
%Title page
\title{QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation}
\subtitle{arXiv:1806.10293, Kalashnikov et al, 2018.}
\author{\textit{Sumamrized by} Hyecheol (Jerry) Jang}
\institute{
  Department of Computer Sciences\\
  University of Wisconsin–Madison
}
\date{RL Paper Study, Jun. 29. 2020}
%End of title page configuration block
%------------------------------------------------------------


%------------------------------------------------------------
%The next block of commands puts the table of contents at the 
%beginning of each section and highlights the current section:

\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Table of Contents}
    \tableofcontents[currentsection]
  \end{frame}
}
%------------------------------------------------------------


%---------------------------------------------------------
%This block defines the existing sections
\newcommand{\firstSec}{Motivation}
\newcommand{\secondSec}{Goal}
% \newcommand{\nthSec}[n]{nth Section}
%---------------------------------------------------------


\begin{document}
  %The next statement creates the title page.
  \frame{\titlepage}

  % Section 1, Motivation
  \section{\firstSec}
    \begin{frame}
      \frametitle{\firstSec : Why Robotics + Reinforcement Learning}
      \begin{itemize}
        \item Usually, Robots are good at \textbf{repetitive tasks} (e.g. Assembly Line)
              \pause
        \item Want to make Robots that \textbf{identifies surroundings} and \textbf{behave accordingly},
              but it is difficult
              \pause
        \begin{itemize}
          \item \textbf{Deep Learning}\\
                Provide ability to handling real-world scenarios
          \item \textbf{Reinforcement Learning}\\
                Provide ability to make decision in long-term,
                using previous experiences in complex and robust scenarios
        \end{itemize}
        \pause
        \item Combining two techniques
        \begin{itemize}
          \item Able to learn policy continuously from their experience
          \item No need for manual engineering, use data they collects
        \end{itemize}
      \end{itemize}
    \end{frame}

    \begin{frame}
      \frametitle{\firstSec : Difficulites of Using RL in Robotics}
      \begin{itemize}
        \item Varience in \textbf{visual and physical property of objects}
        \pause
        \begin{itemize}
          \item Hardness of object (Soft or Hard)
          \item Surface Characteristics (Slippery, Sticky, \ldots)
          \item Color Variation
          \item Shape Variation
          \item \ldots
        \end{itemize}
        \pause
        \item \textbf{Noise} of sensors
      \end{itemize}
      \pause
      \begin{itemize}
        \setlength{\itemindent}{.3in}
        \item[$\Rightarrow$] Still hard to handle though we have sufficiently large training set
        \begin{itemize}
          \setlength{\itemindent}{0.3in}
          \item[$\Rightarrow$] Collecting those training set is expensive (real experiments) 
        \end{itemize}
        \pause
        \item[$\Rightarrow$] Lots of researchers focused on reusing pervious experiences
      \end{itemize} 
    \end{frame}

    \begin{frame}
      \frametitle{\firstSec : Previous Works}
      \begin{itemize}
        \item Focused on learning narrow, individual tasks
        \begin{itemize}
          \item hitting a ball
          \item opening door
          \item throwing objects
          \item \ldots
        \end{itemize}
        \pause
      \end{itemize}
      \begin{itemize}
        \setlength{\itemindent}{.3in}
        \item[$\Rightarrow$] Use \textbf{Grasping} to achieve \textit{generalization}
      \end{itemize}
      \pause
      \begin{itemize}
        \item Approached the grasping task as predicting a \textit{grasp pose}
        \begin{enumerate}
          \item Observe the scene (\textit{Normally, using a depth camera})
          \item Choose best location to grasp
          \item Reach the location (open-loop setting)
        \end{enumerate}
        \pause
        \begin{itemize}
          \item Different with how humans and animals behave
          \item Grasp is a \textbf{dynamical process} that sence and control at each stage
        \end{itemize}
      \end{itemize}
      \pause
      \begin{itemize}
        \setlength{\itemindent}{.3in}
        \item[$\Rightarrow$] \textbf{Where this researches start!!}
      \end{itemize}
    \end{frame}
  % End of Section 1


  % Section 2: Goal
  \section{\secondSec}
  \begin{frame}
    \frametitle{\secondSec}
    \centering
    \Large{Use Reinforcement Learning with Deep Neural Network\\
           to \textbf{perform pre-grasp manipulation}, \\
           \textbf{response to dynamic disturbances}, \\
           and \textbf{learn grasping in a generic framework} \\
           that makes minimal assumptions about the task}
  \end{frame}

  \begin{frame}
    \frametitle{\secondSec : Constraint/Condition + Literature Review}
    \begin{itemize}
      \item \textbf{Closed-loop condition} (With feedback, \textit{\scriptsize{Morrison, et al.}})
      \begin{itemize}
        \item For the other papers work on closed-loop grasping, they deals with servoing problems.
        \item This paper focuses on making generalized RL algorithm
        \item In practice, it makes Kalashnikov et al.'s method (this method)
              to autonomously acquire complicated grasping strategy
      \end{itemize}
      \pause
      \item \textbf{Self-supervised} learning task
      \begin{itemize}
        \item Compare to prevoius work(by Zeng et al.), Kalashnikov et al. utilize more general action space
        \item Actions consist of end-effector \textbf{Cartesian motion} and \textbf{gripper opening/closing}
      \end{itemize}
      \pause
      \item Observation comes from \textbf{a single RGB camera} over the sholder
      \begin{itemize}
        \item Many current grasping system utilizes depth sensing
        \item Using wrist-mounted cameras
      \end{itemize}
    \end{itemize}
  \end{frame}
  % End of Section 2

  % Endings: References
  \begin{frame}
    \frametitle{References}
    \begin{itemize}
      \item Kalashnikov, Dmitry, et al. QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation. 28 Nov. 2018, arxiv.org/abs/1806.10293.
      \item Irpan, Alex, and Peter Pastor. Scalable Deep Reinforcement Learning for Robotic Manipulation. 28 June 2018, ai.googleblog.com/2018/06/scalable-deep-reinforcement-learning.html.
      \item Morrison, Douglas, et al. “Closing the Loop for Robotic Grasping: A Real-Time, Generative Grasp Synthesis Approach.” Robotics: Science and Systems XIV, 2018, doi:10.15607/rss.2018.xiv.021.
    \end{itemize}
  \end{frame}

\end{document}
